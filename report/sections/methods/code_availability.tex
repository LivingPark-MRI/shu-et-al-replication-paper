We used Pandas v.1.4.3 and Numpy v1.22.4 to construct the cohorts. The extraction of WM using SPM12 was carried out by running the Boutiques tool with DOI 10.5281/zenodo.6881412 using Docker v20.10.12 and Boutiques v0.5.25~\cite{tristan_glatard_2022_6881412}. The construction of the cohort, extraction of radiomics features, and training of the ML models were performed on a local computer using Ubuntu OS version 22.04. 

All our methods are available in a publicly available notebook (\url{https://github.com/LivingPark-MRI/shu-etal}). To comply with PPMI's Data Usage Agreements that prevent users from re-publishing data, the notebook queries and downloads data directly from PPMI. Since PPMI does not have a data access API, we developed our own Python interface to PPMI using Selenium, a widely-supported Python library to automate web browser navigation. Using this interface, the notebook downloads PPMI study and imaging files to build the cohorts and train the ML models. The utility functions to download and manipulate PPMI data are implemented in LivingPark utils, a Python package available on GitHub (\url{https://github.com/LivingPark-MRI/livingpark-utils}).

The extension for PyRadiomics can be found at: \url{https://github.com/LivingPark-MRI/shu-etal/blob/main/code/scripts/RadiomicsHelper.py}.